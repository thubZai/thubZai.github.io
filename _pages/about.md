---
permalink: /
title: 
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---  

![multimodality](Untitled design.png){: .align-center width="1111px"}  

True intelligence emerges when neural nets can perceive and reason across modalities (vision, language & action), autonomously invent novel tasks, learn to solve them and adapt in unfamiliar, real-world environments. My current interests include: 

- *Vision‚ÄìLanguage integration (VLMs, MLLMs, VLAMs)*
- *Reinforcement and Open-ended Learning that enable agents to self-generate tasks and progressively bootstrap competence across changing environments* 
- *Multimodal perception (object-centric, 3D-aware perception for improving compositional/spatial reasoning and scene understanding)*

I believe progress here could meaningfully accelerate scientific discovery, embodied AI, and healthcare at scale. The impact could surpass the current aspirations for AGI/ASI. **Open to research collaborations and internships!** 

üìåCheck out [Multimodal/VLMs Research Hub](https://github.com/thubZ09/vision-language-model-hub.git). I thought having a community-driven hub for multimodal researchers would be great. Contributions or suggestions are welcome!

‚úçÔ∏è I enjoy jotting down my thoughts and keeping an organized ‚Äúsecond brain‚Äù, unlike my primary one:) You can find some interesting stuff in the brain dump section above. 

Outside of work, you‚Äôll find me clicking random pictures, reading, trekking or playing and watching a variety of sports (football, cricket, MMA, & Esports).